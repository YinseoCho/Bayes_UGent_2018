Model comparison approach to ANOVA
========================================================
author: Ivan Grahek
date: Ghent University (Belgium)
autosize: true
transition: none
width: 1600
height: 1000
css: css-file.css

Contents
========================================================
incremental: true
type: lineheight

- Model comparison approach to data analysis
- Regression 101 (2 continuous variables)
- Regression with categorical variables
- Model comparison approach to ANOVA

```{r setup, include = FALSE}
library(tidyverse)
set.seed(9992)
```

The standard way: IF-THEN cookbook
========================================================
incremental: true
type: lineheight

<div align = "center" style="float: bottom;">
<img src = "cookbook.jpg" width=924 height=742,5 >
</div>

The model comparison approach: Linear models all the way down
========================================================
incremental: true
type: lineheight

<div align = "center" style="float: bottom;">
<img src = "elephants.jpg" width=800 height=800>
</div>

The model comparison approach
========================================================
incremental: true
type: lineheight

- Most of the analyses can be viewed as comparisons between different linear models
- t-test: two-level categorical variable as the predictor
- ANOVA: three-or-more-level categorical variable as the predictor
- Good introductions: 
    - Judd, McClelland, & Ryan (1989; 2017 - 3rd edition)
    - McElreath (2015)

What is a model?
========================================================
incremental: true
type: lineheight

<div align = "center" style="float: bottom;">
<img src = "pasta.jpg" width = 600 height = 600>
</div>

Compact description of data

Each of the cookbook procedures contains off-the-shelf models hidden inside

Here we will try to open these pasta machines 

Simple regression
========================================================
incremental: true
type: lineheight

What is a linear model?

$$
\begin{align}
\text{DATA} = \text{MODEL} + \text{ERROR} \\ 
\end{align}
$$

We will write this down as:

$$
\begin{align}

\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1}x_{i} \\

\end{align}
$$

A lot of ways to write the same equation:

$$
\begin{align}

\mu_{i} &= \alpha + \beta_{1}x_{i} + \epsilon_{1} \\
\mathcal \epsilon_{i} &\sim \mathrm{Normal}(0,\sigma) \\

\end{align}
$$

Simple regression
========================================================
incremental: true
type: lineheight

How do we write this in R?

$$
\begin{align}

\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1}x_{i} \\

\end{align}
$$


```{r, message = FALSE, eval=FALSE} 
model <- lm(y ~ 1 + x, data = d)
```

Simple regression
========================================================
incremental: true
type: lineheight

$$
\begin{align}
\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1}x_{i} \\
\end{align}
$$

Our goal is always to estimate these parameters:

$$
\begin{align}

\alpha\\
\beta_{1}\\

\end{align}
$$

This is what we call "fitting a model to the data"

Let's get some data
========================================================
incremental: true
type: lineheight

Here is some fascinating data on properties of cars

```{r, message = FALSE} 
head (mtcars)
```

Let's plot the data
========================================================
incremental: true
type: lineheight

A simple scatterplot

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9}  
# Basic scatter plot
ggplot(mtcars, aes(x=wt, y=mpg)) + 
  geom_point() + # Data points
  theme_bw(base_size = 20) # Theme
```

Fitting the simplest model 
========================================================
incremental: true
type: lineheight

$$
\begin{align}
\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha \\
\end{align}
$$

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9}  
# Basic scatter plot
ggplot(mtcars, aes(x=wt, y=mpg)) + 
  geom_point() + # Data points
  labs(x="Car Weight", y = "Miles Per Gallon") + # Name the axes
  theme_bw(base_size = 20) + # Theme for the plot
  geom_smooth(method = lm, se=FALSE, formula = y ~ 1)  # Regression line
```

How bad is the model? 
========================================================
incremental: true
type: lineheight

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9}  
model <- lm(mpg ~ 1, data = mtcars)
# Quick look at the actual, predicted, and residual values
library(tidyverse)
d = mtcars %>% 
    mutate(
      predicted = predict(model),   # Save the predicted values
      residuals = residuals(model) # Save the residual values  
 )%>%
  select(wt, mpg, predicted, residuals) 

sample_n(d, 10)
```
How bad is the model? 
========================================================
incremental: true
type: lineheight

Plot the residuals

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9}  
ggplot(d, aes(x = wt, y = mpg)) +
  geom_smooth(method = lm, se = FALSE, formula = y ~ 1, color = "black") +  # Regression line
  geom_segment(aes(xend = wt, yend = predicted), alpha = .2) +  # Connect predicted and actual values
  geom_point() + # Data points
  geom_point(aes(y = predicted), shape = 1) + #Points for values predicted by the model
  xlab("Car Weight") + # X-axis
  ylab("Miles Per Gallon") + # Y-axis
  theme_bw(base_size = 20)  # Theme for the plot
```

What does our model think? 
========================================================
incremental: true
type: lineheight


```{r, message = FALSE} 
model <- lm(mpg ~ 1, data = mtcars)
summary(model)
```

Fitting the second simplest model
========================================================
incremental: true
type: lineheight

$$
\begin{align}
\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1}x_{i} \\
\end{align}
$$

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9}  
# Basic scatter plot
ggplot(mtcars, aes(x=wt, y=mpg)) + 
  geom_point() + # Data points
   # Regression line
  labs(x="Car Weight", y = "Miles Per Gallon") + # Name the axes
  theme_bw(base_size = 20) + # Theme for the plot
  geom_smooth(method = lm, se=FALSE, color = "black", formula = y ~ 1 + x) # Regression line
```

How bad is the model? 
========================================================
incremental: true
type: lineheight

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9}  
model <- lm(mpg ~ 1 + wt, data = mtcars)
# Quick look at the actual, predicted, and residual values
library(tidyverse)
d <- mtcars %>% 
    mutate(
      predicted = predict(model),   # Save the predicted values
      residuals = residuals(model) # Save the residual values  
 )%>%
  select(wt, mpg, predicted, residuals) 

sample_n(d, 10)
```
How bad is the model? 
========================================================
incremental: true
type: lineheight

Plot the residuals

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9}  
ggplot(d, aes(x = wt, y = mpg)) +
  geom_smooth(method = lm, se = FALSE, color = "black", formula = y ~ 1 + x) +  # Regression line
  geom_segment(aes(xend = wt, yend = predicted), alpha = .2) +  # Connect predicted and actual values
  geom_point() + # Data points
  geom_point(aes(y = predicted), shape = 1) + #Points for values predicted by the model
  xlab("Car Weight") + # X-axis
  ylab("Miles Per Gallon") + # Y-axis
  theme_bw()  # Theme for the plot
```

What does our model think? 
========================================================
incremental: true
type: lineheight

```{r, message = FALSE} 
model <- lm(mpg ~ 1 + wt, data = mtcars)
  
summary(model)
```

How do we estimate the intercept and the slope? 
========================================================
incremental: true
type: lineheight

The goal is to find a set of parameters that minimize the residuals

Moving the line until we find the model with minimal errors

```{r eval = TRUE, echo = FALSE, fig.align = "center", fig.width = 9, fig.height = 9}  
# Basic scatter plot
ggplot(mtcars, aes(x=wt, y=mpg)) + 
  geom_point() + # Data points
   # Regression line
  labs(x="Car Weight", y = "Miles Per Gallon") + # Name the axes
  theme_bw(base_size = 20) + # Theme for the plot
  geom_smooth(method = lm, se=FALSE, color = "black", formula = y ~ 1 + x) # Regression line
```


How do we estimate the intercept and the slope? 
========================================================
incremental: true
type: lineheight

We can quantify these errors as the Sum of Squared Errors (SSE) 

```{r, message = FALSE}
model <- lm(mpg ~ 1 + wt, data = mtcars)
# Quick look at the actual, predicted, and residual values
library(tidyverse)
d <- mtcars %>% 
    mutate(
      predicted = predict(model),   # Save the predicted values
      residuals = residuals(model) # Save the residual values  
 )%>%
  select(wt, mpg, predicted, residuals)

sample_n(d,10)

SSE <- sum(d$residuals^2) # Sum of squared errors
SSE
```

Assumptions that need to be met
========================================================
incremental: true
type: lineheight

Normality of residuals
  - Errors are normally distributed

Homogenity of variances
  - Across groups

Independence of the residuals
  - We shouldn't be able to predict residuals of an observation from other residuals 
  
Model comparison
========================================================
incremental: true
type: lineheight

Compact and augmented model

```{r eval = TRUE, echo = FALSE, fig.align = "center", fig.width = 18, fig.height = 9,fig.show='hold'}  
library(gridExtra)
# Basic scatter plot
p1 <- ggplot(mtcars, aes(x=wt, y=mpg)) + 
  geom_point() + # Data points
   # Regression line
  labs(x="Car Weight", y = "Miles Per Gallon") + # Name the axes
  theme_bw(base_size = 20) + # Theme for the plot
  geom_smooth(method = lm, se=FALSE, color = "black", formula = y ~ 1) +  # Regression line
  ggtitle("Compact")

# Basic scatter plot
p2 <- ggplot(mtcars, aes(x=wt, y=mpg)) + 
  geom_point() + # Data points
   # Regression line
  labs(x="Car Weight", y = "Miles Per Gallon") + # Name the axes
  theme_bw(base_size = 20) + # Theme for the plot
  geom_smooth(method = lm, se=FALSE, color = "black", formula = y ~ 1 + x) + # Regression line
  ggtitle("Augmented")

grid.arrange(p1,p2, ncol=2)
  
```

Model comparison
========================================================
incremental: true
type: lineheight

Let's calculate the SSEs of these two models

```{r, message = FALSE}
Compact_model <- lm(mpg ~ 1, data = mtcars)
# Quick look at the actual, predicted, and residual values
library(tidyverse)
d_C <- mtcars %>% 
    mutate(
      predicted = predict(Compact_model),   # Save the predicted values
      residuals = residuals(Compact_model) # Save the residual values  
 )

SSE_Compact <- sum(d_C$residuals^2) # Sum of squared errors
SSE_Compact
```

```{r, message = FALSE}
Augmented_model <- lm(mpg ~ 1 + wt, data = mtcars)
# Quick look at the actual, predicted, and residual values
library(tidyverse)
d_A = mtcars %>% 
    mutate(
      predicted = predict(Augmented_model),   # Save the predicted values
      residuals = residuals(Augmented_model) # Save the residual values  
 )

SSE_Augmented <- sum(d_A$residuals^2) # Sum of squared errors
SSE_Augmented
```

Model comparison
========================================================
incremental: true
type: lineheight

Proportional reduction in error 

How much (proportion) does the error reduce when we introduce an additional predictor?

$$
\begin{align}
\text{PRE} = (\text{SSE_C} - \text{SSE_A}) / \text{SSE_C} \\ 
\end{align}
$$

```{r, message = FALSE, echo = TRUE}
PRE <- (SSE_Compact - SSE_Augmented)/SSE_Compact
PRE
```

Model comparison
========================================================
incremental: true
type: lineheight

F statistic

$$
\begin{align}
\text{F} = \frac{\text{PRE}/(\text{PA} - \text{PC})}{(1-\text{PRE}/(\text{n}-\text{PA})} \\ 
\end{align}
$$

```{r, message = FALSE, echo = TRUE}
F_stat <- (PRE/(2-1))/((1-PRE)/(32-2))
F_stat

Compact_model <- lm(mpg ~ 1, data = mtcars)
Augmented_model <- lm(mpg ~ 1 + wt, data = mtcars)
anova(Compact_model,Augmented_model)
```

Models with categorical predictors 
========================================================
incremental: true
type: lineheight

- Buliding a regression with a categorical predictor
- This is the case of a t-test

Let's get the data from the first lecture
========================================================
incremental: true
type: lineheight

Beer vs. water & positive vs. negative dataset

```{r, message = FALSE} 
d <- read.csv(file = "data_attitude.csv") # Get the data file if you are in the model_comparison_ANOVA WD
#d <- read.csv(file = "day_1_model_comparison_ANOVA/data_attitude.csv") # Get the data file if you are in the Bayes_UGent_2018 WD
head (d)
```

Let's plot the data
========================================================
incremental: true
type: lineheight

A simple scatterplot

```{r, message = FALSE, fig.width = 9, fig.heigth = 9, fig.align = "center"}  
library(tidyverse)
ggplot(d, aes(x = drink, y = ratings)) +
    geom_point() + 
    theme_bw(base_size = 20)
```

Dummy coding
========================================================
incremental: true
type: lineheight

Our predictor is a categorical variable, how do we enter this is a regression?

We have to somehow turn them into numbers

Dummy coding: We have two categories, let beer be zero!

For beer:
$$
\begin{align}
\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1}beer \\ &= \alpha + 0 \\ &= \alpha
\end{align}
$$

For water:
$$
\begin{align}
\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1}water \\  &= \alpha + \beta_{1}
\end{align}
$$

Dummy coding
========================================================
incremental: true
type: lineheight

How do we interpret the results?

Intercept will be the estimate of beer, slope will be the difference between beer and water

```{r eval = TRUE, echo = TRUE} 
model_dummy <- lm(ratings ~ drink, data = d)
summary(model_dummy)
```

Contrast coding
========================================================
incremental: true
type: lineheight

The values of contrast variables across the two categories sum to zero

```{r eval = TRUE, echo = FALSE, fig.align = "center", fig.width = 9, fig.height = 9} 
d_contrast <- d %>% 
    mutate(
      drink = ifelse(d$drink == "beer", -0.5, 0.5),   # Contrast coding
      ) 

ggplot(d_contrast, aes(x = drink, y = ratings)) +
    geom_point() + 
    geom_smooth(method = lm, se=FALSE, color = "black", formula = y ~ 1 + x)+#+
    theme_bw(base_size = 20)
```
    
Contrast coding
========================================================
incremental: true
type: lineheight

How do the equations look like?

For beer:

$$
\begin{align}
\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{beer} &= \alpha + \beta_{1}-0.5 \\ &= \alpha - \beta_{1}/2
\end{align}
$$

For water:

$$
\begin{align}
\mathcal y_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{water} &= \alpha + \beta_{1}0.5 \\ &= \alpha + \beta_{1}/2
\end{align}
$$

Contrast coding
========================================================
incremental: true
type: lineheight

How do we interpret the results?

Intercept is the average of the two group means

Slope is the difference between the two means (different if codes are -1 and 1, but same F statistic)

```{r eval = TRUE, echo = TRUE} 
model_contrast <- lm(ratings ~ drink, data = d_contrast)
summary(model_contrast)
```

Full ANOVA 
========================================================
incremental: true
type: lineheight

Which models are contained in the 2X2 ANOVA?

$$
\begin{align}

\mathcal{Null} : \text{ratings}_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha \\
\\
\mathcal{Drink} : \text{ratings}_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1} \text{drink}_{i} \\
\\
\mathcal{Imagery} : \text{ratings}_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1} \text{imagery}_{i} \\
\\
\mathcal{Main effects} : \text{ratings}_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1} \text{drink}_{i} + \beta_{2} \text{imagery}_{i}  \\
\\
\mathcal{Interactions} : \text{ratings}_{i} &\sim \mathrm{Normal}(\mu_{i},\sigma) \\
\mu_{i} &= \alpha + \beta_{1} \text{drink}_{i} + \beta_{2} \text{imagery}_{i} + \beta_{3} \text{drink}_{i} \times \text{imagery}_{i} \\

\end{align}
$$

Full ANOVA in lm
========================================================
incremental: true
type: lineheight

How do we write this in R?

```{r eval = TRUE, echo = TRUE} 
model_null <- lm(ratings ~ 1, data = d)
model_drink <- lm(ratings ~ drink, data = d)
model_imagery <- lm(ratings ~ imagery, data = d)
model_maineffects <- lm(ratings ~ drink + imagery, data = d)
model_interaction <- lm(ratings ~ drink * imagery, data = d)
```

Exercise 
========================================================
incremental: true
type: lineheight

Take the exercise data (2X2 water and imagery)

Fit all of the ANOVA models and check which one has the loewst R squared 
    - Contrast code both drink and imagery!

Calculate PRE and F statistic comparing the interaction and the two main effects model

Solutions 
========================================================
incremental: true
type: lineheight

Contrast coding

```{r eval = TRUE, echo = TRUE, fig.align = "center", fig.width = 9, fig.height = 9} 
library(tidyverse)
d_contrast <- d %>% 
    mutate(
      drink = ifelse(d$drink == "beer", -0.5, 0.5),   # Contrast coding
      imagery = ifelse(d$imagery == "neutral", -0.5, 0.5),   # Contrast coding
            ) 
```

All the ANOVA models

```{r eval = TRUE, echo = TRUE} 
model_null <- lm(ratings ~ 1, data = d_contrast)
model_drink <- lm(ratings ~ drink, data = d_contrast)
model_imagery <- lm(ratings ~ imagery, data = d_contrast)
model_maineffects <- lm(ratings ~ drink + imagery, data = d_contrast)
model_interaction <- lm(ratings ~ drink * imagery, data = d_contrast)
```

Compare the models with ANOVA

```{r eval = TRUE, echo = TRUE} 
anova(model_maineffects, model_interaction)
```

Model comparison
========================================================
incremental: true
type: lineheight

Let's calculate the SSEs of these two models

```{r, message = FALSE}
model_maineffects <- lm(ratings ~ drink + imagery, data = d_contrast)
# Quick look at the actual, predicted, and residual values
library(tidyverse)
d_main = d_contrast %>% 
    mutate(
      predicted = predict(model_maineffects),   # Save the predicted values
      residuals = residuals(model_maineffects) # Save the residual values  
 )

SSE_Main <- sum(d_main$residuals^2) # Sum of squared errors
SSE_Main
```

```{r, message = FALSE}
model_interaction <- lm(ratings ~ drink * imagery, data = d_contrast)
# Quick look at the actual, predicted, and residual values
library(tidyverse)
d_interaction <- d_contrast %>% 
    mutate(
      predicted = predict(model_interaction),   # Save the predicted values
      residuals = residuals(model_interaction) # Save the residual values  
 )

SSE_Interaction <- sum(d_interaction$residuals^2) # Sum of squared errors
SSE_Interaction
```

Model comparison
========================================================
incremental: true
type: lineheight

Proportional reduction in error 

How much (proportion) does the error reduce when we introduce an additional predictor?

$$
\begin{align}
\text{PRE} = (\text{SSE_C} - \text{SSE_A}) / \text{SSE_C} \\ 
\end{align}
$$

```{r, message = FALSE, echo = TRUE}
PRE <- (SSE_Main - SSE_Interaction)/SSE_Main
PRE
```

Model comparison
========================================================
incremental: true
type: lineheight

F statistic

$$
\begin{align}
\text{F} = \frac{\text{PRE}/(\text{PA} - \text{PC})}{(1-\text{PRE}/(\text{n}-\text{PA})} \\ 
\end{align}
$$

```{r, message = FALSE, echo = TRUE}
F_stat <- (PRE/(4-3))/((1-PRE)/(80-4))
F_stat

anova(model_maineffects,model_interaction)

```




<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script>

for(i=0;i<$("section").length;i++) {
if(i==0) continue
$("section").eq(i).append("<p style='font-size:xx-large;position:fixed;right:30px;bottom:30px;'>" + i + "</p>")
}

</script>
